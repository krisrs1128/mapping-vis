---
title: "R Notebook"
output: html_notebook
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```
```{r}
library("EBImage")
library("purrr")
library("torch")
library("torchvision")
```

```{r}
initializer <- function(x_paths, y_paths) {
  self$paths <- data.frame("x" = x_paths, "y" = y_paths)
}

augment <- function(x, y, imsize=512) {
  p_v <- sample(c(0, 1), 1)
  p_h <- sample(c(0, 1), 1)
  cix <- map(dim(x)[-1], ~ sample(1:(. - imsize), 1)) %>%
    as.numeric()
  
  list(x, y) %>%
    map(~ transform_random_vertical_flip(., p = p_v)) %>%
    map(~ transform_random_horizontal_flip(., p = p_h)) %>%
    map(~ transform_crop(., top = cix[1], left = cix[2], height = imsize, width = imsize))
}

getitem <- function(i) {
  x <- get(load(self$paths$x[i])) %>%
    transform_to_tensor()
  y <- get(load(self$paths$y[i])) %>%
    transform_to_tensor()
  augment(x, y)
}
```


```{r}
glacier_data <- dataset(
  name = "glaciers",
  initialize = initializer,
  .getitem = getitem,
  .length = function() { nrow(self$paths) }
)
```

```{r}
data_dir <- file.path("/Users/kris/Desktop/teaching/mapping-vis/data/processed/")
x_paths <- list.files(data_dir, "x-*", full = TRUE)
y_paths <- list.files(data_dir, "y-*", full = TRUE)
ds <- glacier_data(x_paths, y_paths)
```

```{r}
ix <- 2
batch <- ds[ix]

to_image <- function(x) {
  as.array(x) %>%
    aperm(c(2, 3, 1)) %>%
    Image()
}

to_rgb <- function(x, ch = c(1, 2, 3)) {
  x <- as.array(x)
  rgbImage(x[ch[1],, ], x[ch[2],, ], x[ch[3],, ])
}

to_image(batch[[1]]) %>%
  display()
to_image(batch[[2]]) %>%
  display()
to_rgb(batch[[1]], c(5, 4, 2)) %>%
  display()
```

```{r}
loaders <- list(
  "train" = dataloader(ds, batch_size=2), 
  "test" = dataloader(ds, batch_size=2)
)
```

```{r}
unet <- nn_module(
  "unet",
  
  initialize = function(channels_in = 13,
                        n_classes = 2,
                        depth = 5,
                        n_filters = 6) {
    
    self$down_path <- nn_module_list()
    
    prev_channels <- channels_in
    for (i in 1:depth) {
      self$down_path$append(down_block(prev_channels, 2 ^ (n_filters + i - 1)))
      prev_channels <- 2 ^ (n_filters + i -1)
    }
    
    self$up_path <- nn_module_list()
    
    for (i in ((depth - 1):1)) {
      self$up_path$append(up_block(prev_channels, 2 ^ (n_filters + i - 1)))
      prev_channels <- 2 ^ (n_filters + i - 1)
    }
    
    self$last = nn_conv2d(prev_channels, n_classes, kernel_size = 1)
  },
  
  forward = function(x) {
    
    blocks <- list()
    
    for (i in 1:length(self$down_path)) {
      x <- self$down_path[[i]](x)
      if (i != length(self$down_path)) {
        blocks <- c(blocks, x)
        x <- nnf_max_pool2d(x, 2)
      }
    }
    
    for (i in 1:length(self$up_path)) {  
      x <- self$up_path[[i]](x, blocks[[length(blocks) - i + 1]]$to(device = device))
    }
    
    # softmax along 2nd (channel) dimension
    sigma <- nn_softmax(2)
    sigma(self$last(x))
  }
)
```
```{r}
down_block <- nn_module(
  "down_block",
  
  initialize = function(in_size, out_size) {
    self$conv_block <- conv_block(in_size, out_size)
  },
  
  forward = function(x) {
    self$conv_block(x)
  }
)

up_block <- nn_module(
  "up_block",
  
  initialize = function(in_size, out_size) {
    
    self$up = nn_conv_transpose2d(in_size,
                                  out_size,
                                  kernel_size = 2,
                                  stride = 2)
    self$conv_block = conv_block(in_size, out_size)
  },
  
  forward = function(x, bridge) {
    
    up <- self$up(x)
    torch_cat(list(up, bridge), 2) %>%
      self$conv_block()
  }
)

conv_block <- nn_module( 
  "conv_block",
  
  initialize = function(in_size, out_size) {
    
    self$conv_block <- nn_sequential(
      nn_conv2d(in_size, out_size, kernel_size = 3, padding = 1),
      nn_relu(),
      nn_dropout(0.6),
      nn_conv2d(out_size, out_size, kernel_size = 3, padding = 1),
      nn_relu()
    )
  },
  
  forward = function(x){
    self$conv_block(x)
  }
)
```

```{r}
dice_loss_ <- function(y_hat, y, smooth = 1) {
  1 - ((2 * (y_hat * y)$sum() + smooth) / (y_hat$sum() + y$sum() + smooth))
}
```


```{r}
dice_loss <- function(y_hat, y, smooth = 1, weights = c(0.4, 0.6)) {
  K <- dim(y)[2]
  losses <- torch_zeros(K)
  for (k in seq_len(K)) {
    res <- dice_loss_(y_hat[,k,,], y[,k,,], smooth = smooth)
    losses[k] <- res
  }
  (weights * losses)$sum()
}
```

```{r}
train_epoch <- function(model, opt, loaders, scheduler, device) {
  model$train()
  losses <- list("train" = c(), "test" = c())
  for (xy in enumerate(loaders$train)) {
    opt$zero_grad()
    y_hat <- model(xy[[1]]$to(device))
    y <- xy[[2]]$to(device)
  
    loss <- dice_loss(y_hat, y)
    loss$backward()
    opt$step()
    scheduler$step()

    losses$train <- append(losses$train, loss$item())
  }
  
  list(model, losses)
}

```

```{r}
n_epoch <- 20
device <- torch_device(if(cuda_is_available()) "cuda" else "cpu")
model <- unet(depth = 4)$to(device = device)
opt <- optim_sgd(model$parameters, lr = 0.1, momentum = 0.9)
scheduler <- lr_one_cycle(opt, max_lr = 0.1, steps = length(loaders$train), epochs = n_epoch)
train_epoch(model, opt, loaders, scheduler, device)
```

